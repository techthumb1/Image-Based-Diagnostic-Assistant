{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mZwkNWicXj1k"
      },
      "outputs": [],
      "source": [
        "#!pip install nibabel monai torch pydicom torchvision transformers tensorflow\n",
        "#!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "09SKvbwYGJRZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import jaccard_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY3tOhbJX01x"
      },
      "outputs": [],
      "source": [
        "# Function to load and resize DICOM images\n",
        "def load_and_resize_dicom_images(folder_path, target_size=(256, 256)):\n",
        "    dicom_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.dcm')]\n",
        "    images = [cv2.resize(pydicom.dcmread(f).pixel_array, target_size) for f in dicom_files]\n",
        "    return np.array(images)\n",
        "\n",
        "# Function to load and resize JPG images\n",
        "def load_and_resize_jpg_images(folder_path, target_size=(256, 256)):\n",
        "    jpg_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.jpg') or f.endswith('.jpeg')]\n",
        "    images = [cv2.resize(cv2.imread(f, cv2.IMREAD_GRAYSCALE), target_size) for f in jpg_files]\n",
        "    return np.array(images)\n",
        "\n",
        "# Assuming the structure as seen in the image\n",
        "base_path = '/content/drive/MyDrive/Brain-MRI-Images-HF/ST000001'\n",
        "subfolders = [os.path.join(base_path, d) for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
        "\n",
        "all_images = []\n",
        "for subfolder in subfolders:\n",
        "    dicom_images = load_and_resize_dicom_images(subfolder)\n",
        "    jpg_images = load_and_resize_jpg_images(subfolder)\n",
        "    all_images.append(dicom_images)\n",
        "    all_images.append(jpg_images)\n",
        "\n",
        "# Flatten the list of images\n",
        "all_images = np.concatenate(all_images, axis=0)\n",
        "\n",
        "# Normalize the images\n",
        "all_images = all_images.astype(np.float32) / np.max(all_images)\n",
        "\n",
        "# Display a sample image to verify loading\n",
        "plt.imshow(all_images[0], cmap='gray')\n",
        "plt.title(\"Sample Image\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C80NxY9Hbee",
        "outputId": "9ab99ced-0237-4ba3-95c0-f4e2beeb72c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(763, 256, 256)\n"
          ]
        }
      ],
      "source": [
        "# Shape of all images\n",
        "print(all_images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJSN3-bzFNyW"
      },
      "source": [
        "### Creating Binary Masks (if necessary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXFGnq85FKuP",
        "outputId": "015015f3-4542-43a1-d159-c2a3349840ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (610, 256, 256, 1)\n",
            "X_val shape: (153, 256, 256, 1)\n",
            "y_train shape: (610, 256, 256, 1)\n",
            "y_val shape: (153, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "def create_binary_masks(images, threshold=0.5):\n",
        "    masks = (images > threshold * np.max(images)).astype(np.float32)\n",
        "    return masks\n",
        "\n",
        "# Create masks using the simple threshold\n",
        "all_masks = create_binary_masks(all_images)\n",
        "\n",
        "# Split images and masks into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(all_images, all_masks, test_size=0.2, random_state=42)\n",
        "\n",
        "# Adjust the shape of the data to include the channel dimension\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)\n",
        "y_train = np.expand_dims(y_train, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bTeMW-tFV7Q"
      },
      "source": [
        "### Build U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "id": "H6-FU-6TFZiM"
      },
      "outputs": [],
      "source": [
        "def unet_model_with_dropout(input_size=(256, 256, 1)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Dropout(0.1)(conv1)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Dropout(0.1)(conv2)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = Dropout(0.2)(conv3)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = Dropout(0.2)(conv4)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = Dropout(0.3)(conv5)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = Concatenate()([UpSampling2D(size=(2, 2))(conv5), conv4])\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
        "    conv6 = Dropout(0.2)(conv6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = Concatenate()([UpSampling2D(size=(2, 2))(conv6), conv3])\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
        "    conv7 = Dropout(0.2)(conv7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = Concatenate()([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
        "    conv8 = Dropout(0.1)(conv8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = Concatenate()([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
        "    conv9 = Dropout(0.1)(conv9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = unet_model_with_dropout()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for early stopping and model checkpointing\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, monitor='val_loss', restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.batchnorm = nn.BatchNorm3d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class nnUNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(nnUNet, self).__init__()\n",
        "        self.conv1 = ConvBlock(in_channels, 32)\n",
        "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        self.conv2 = ConvBlock(32, 64)\n",
        "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        self.conv3 = ConvBlock(64, 128)\n",
        "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        self.conv4 = ConvBlock(128, 256)\n",
        "        self.pool4 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        self.conv5 = ConvBlock(256, 512)\n",
        "        self.upconv4 = nn.ConvTranspose3d(512, 256, kernel_size=2, stride=2)\n",
        "        self.upconv3 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2)\n",
        "        self.upconv2 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)\n",
        "        self.upconv1 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2)\n",
        "        self.conv6 = nn.Conv3d(32, out_channels, kernel_size=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        pool1 = self.pool1(conv1)\n",
        "        conv2 = self.conv2(pool1)\n",
        "        pool2 = self.pool2(conv2)\n",
        "        conv3 = self.conv3(pool2)\n",
        "        pool3 = self.pool3(conv3)\n",
        "        conv4 = self.conv4(pool3)\n",
        "        pool4 = self.pool4(conv4)\n",
        "        conv5 = self.conv5(pool4)\n",
        "        upconv4 = self.upconv4(conv5)\n",
        "        concat4 = torch.cat((upconv4, conv4), dim=1)\n",
        "        upconv3 = self.upconv3(concat4)\n",
        "        concat3 = torch.cat((upconv3, conv3), dim=1)\n",
        "        upconv2 = self.upconv2(concat3)\n",
        "        concat2 = torch.cat((upconv2, conv2), dim=1)\n",
        "        upconv1 = self.upconv1(concat2)\n",
        "        concat1 = torch.cat((upconv1, conv1), dim=1)\n",
        "        output = self.conv6(concat1)\n",
        "        return output\n",
        "    \n",
        "model = nnUNet(1, 1)\n",
        "model = model.cuda()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Convert the numpy arrays to PyTorch tensors\n",
        "X_train_torch = torch.tensor(X_train).permute(0, 3, 1, 2).float().cuda()\n",
        "y_train_torch = torch.tensor(y_train).permute(0, 3, 1, 2).float().cuda()\n",
        "X_val_torch = torch.tensor(X_val).permute(0, 3, 1, 2).float().cuda()\n",
        "y_val_torch = torch.tensor(y_val).permute(0, 3, 1, 2).float().cuda()\n",
        "\n",
        "# Training loop\n",
        "epochs = 50\n",
        "batch_size = 4\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for i in range(0, len(X_train_torch), batch_size):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_train_torch[i:i+batch_size])\n",
        "        loss = criterion(output, y_train_torch[i:i+batch_size])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_val_torch)\n",
        "    loss = criterion(y_pred, y_val_torch)\n",
        "    print(f'Validation Loss: {loss.item()}')\n",
        "\n",
        "# Convert the PyTorch tensors to numpy arrays\n",
        "y_pred = y_pred.cpu().numpy()\n",
        "y_val_torch = y_val_torch.cpu().numpy()\n",
        "\n",
        "# Calculate the Jaccard score\n",
        "y_pred = (y_pred > 0.5).astype(np.float32)\n",
        "jaccard = jaccard_score(y_val_torch.flatten(), y_pred.flatten())\n",
        "print(f'Jaccard Score: {jaccard}')\n",
        "\n",
        "# Display a sample image, ground truth and prediction\n",
        "sample_idx = 0\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(X_val[sample_idx, :, :, 0], cmap='gray')\n",
        "plt.title(\"Image\")\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(y_val[sample_idx, :, :, 0], cmap='gray')\n",
        "plt.title(\"Ground Truth\")\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(y_pred[sample_idx, 0, :, :], cmap='gray')\n",
        "plt.title(\"Prediction\")\n",
        "plt.show()\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "# Load the model\n",
        "model = nnUNet(1, 1)\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model = model.cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i524DKYqo-Fi"
      },
      "source": [
        "### Train and Augment the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Exfl005pD3u"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Apply data augmentation to the training data\n",
        "train_gen = datagen.flow(X_train, y_train, batch_size=32)\n",
        "\n",
        "# Use the augmented data in model training\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=len(X_train) // 32,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIeDOiJXIufH"
      },
      "outputs": [],
      "source": [
        "# Plotting the training history\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='train_loss')\n",
        "    plt.plot(history.history['val_loss'], label='val_loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVitcGCNuMJl"
      },
      "source": [
        "### Visualize Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CHRfHfPwFv8b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to visualize predictions\n",
        "def visualize_prediction(model, image, true_mask=None):\n",
        "    pred_mask = model.predict(np.expand_dims(image, axis=0))[0, :, :, 0]  # Predict the mask and remove batch dimension\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title('Input Image')\n",
        "    plt.imshow(image, cmap='gray')\n",
        "\n",
        "    if true_mask is not None:\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title('True Mask')\n",
        "        plt.imshow(true_mask, cmap='gray')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title('Predicted Mask')\n",
        "    plt.imshow(pred_mask, cmap='gray')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Visualize some predictions\n",
        "for i in range(5):\n",
        "    visualize_prediction(model, X_val[i], y_val[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDVUCpMEo0fs"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNM3kePPox1m"
      },
      "outputs": [],
      "source": [
        "# Function to compute IoU\n",
        "def compute_iou(y_true, y_pred):\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = (y_pred.flatten() > 0.5).astype(np.int32)\n",
        "    return jaccard_score(y_true, y_pred)\n",
        "\n",
        "# Evaluate model on validation set\n",
        "val_predictions = model.predict(X_val)\n",
        "iou_scores = [compute_iou(y_val[i], val_predictions[i]) for i in range(len(y_val))]\n",
        "\n",
        "print(f'Mean IoU on validation set: {np.mean(iou_scores)}')\n",
        "\n",
        "# Visualize some predictions\n",
        "for i in range(5):\n",
        "    visualize_prediction(model, X_val[i], y_val[i])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
