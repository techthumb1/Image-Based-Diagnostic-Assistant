{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUCK-Net for Medical Image Segmentation\n",
    "\n",
    "DUCK-Net is a deep learning model specifically designed for medical image segmentation tasks. It is widely used in the field of medical imaging to accurately identify and segment different structures or regions of interest within medical images.\n",
    "\n",
    "To utilize DUCK-Net for medical image segmentation, we need to import the following libraries:\n",
    "\n",
    "- **TensorFlow**: A popular deep learning framework that provides the necessary tools and functionalities for building and training neural networks.\n",
    "- **Keras**: A high-level API built on top of TensorFlow that simplifies the process of building and training deep learning models.\n",
    "- **NumPy**: A fundamental package for scientific computing in Python, used for handling multi-dimensional arrays and performing numerical operations.\n",
    "- **Matplotlib**: A plotting library that allows us to visualize the medical images and the segmentation results.\n",
    "\n",
    "By leveraging these libraries, we can effectively implement and train DUCK-Net for medical image segmentation tasks, enabling accurate and efficient analysis of medical images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import gc\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import CSVLogger\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "from model_architecture.dice_loss import dice_metric_loss\n",
    "from model_architecture import DUCK_Net\n",
    "from image_loader import image_loader2d\n",
    "\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")\n",
    "print(f\"Albumentations version: {A.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of GPUs available\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the model parameters\n",
    "\n",
    "img_size = 352\n",
    "dataset_type = 'kvasir' # Options: kvasir/cvc-clinicdb/cvc-colondb/etis-laribpolypdb\n",
    "learning_rate = 1e-4\n",
    "seed_value = 58800\n",
    "filters = 17 # Number of filters, the paper presents the results with 17 and 34\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "ct = datetime.now()\n",
    "\n",
    "model_type = \"DuckNet\"\n",
    "\n",
    "progress_path = 'ProgressFull/' + dataset_type + '_progress_csv_' + model_type + '_filters_' + str(filters) +  '_' + str(ct) + '.csv'\n",
    "progressfull_path = 'ProgressFull/' + dataset_type + '_progress_' + model_type + '_filters_' + str(filters) + '_' + str(ct) + '.txt'\n",
    "plot_path = 'ProgressFull/' + dataset_type + '_progress_plot_' + model_type + '_filters_' + str(filters) + '_' + str(ct) + '.png'\n",
    "model_path = 'ModelSaveTensorFlow/' + dataset_type + '/' + model_type + '_filters_' + str(filters) + '_' + str(ct)\n",
    "\n",
    "EPOCHS = 600\n",
    "min_loss_for_saving = 0.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
